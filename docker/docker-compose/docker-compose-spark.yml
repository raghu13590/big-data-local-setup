services:
  spark-master:
    image: bitnami/spark:latest
    container_name: spark-master
    environment:
      - HADOOP_CONF_DIR=/opt/bitnami/hadoop/conf
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_PUBLIC_DNS=localhost
      - SPARK_CONF_spark_ui_reverseProxy=true
      - SPARK_MASTER_WEBUI_PORT=8082
      - SPARK_CONF_DIR=/opt/bitnami/spark/conf
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=file:/opt/bitnami/spark/history
    ports:
      - "8082:8082"
    volumes:
      - ../configs/spark:/opt/bitnami/spark/conf
      - ../app-data/spark/jars:/opt/bitnami/spark/custom-jars
      - ../app-data/spark:/opt/bitnami/spark/data
      - ../configs/hadoop/hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml
      - ../app-data/spark/history:/opt/bitnami/spark/history
    networks:
      - big-data-network
    healthcheck:
      test: ["CMD-SHELL", "python3 -c 'import urllib.request as urllib; import json; res = urllib.urlopen(\"http://localhost:8082/json/\"); data = json.load(res); exit(0) if data[\"status\"] == \"ALIVE\" else exit(1)'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 5s

  spark-history:
    image: bitnami/spark:latest
    container_name: spark-history
    environment:
      - SPARK_HISTORY_OPTS=-Dspark.history.fs.logDirectory=file:/opt/bitnami/spark/history
    ports:
      - "18080:18080"
    volumes:
      - ../app-data/spark/history:/opt/bitnami/spark/history
    networks:
      - big-data-network
    command: "/opt/bitnami/spark/sbin/start-history-server.sh"

  spark-worker-1:
    image: bitnami/spark:latest
    container_name: spark-worker-1
    environment:
      - HADOOP_CONF_DIR=/opt/bitnami/hadoop/conf
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_PUBLIC_DNS=localhost
      - SPARK_CONF_spark_ui_reverseProxy=true
      - SPARK_WORKER_WEBUI_PORT=8083
    depends_on:
      - spark-master
    ports:
      - "8083:8083"
    volumes:
      - ../configs/spark:/opt/bitnami/spark/conf
      - ../app-data/spark/jars:/opt/bitnami/spark/custom-jars
      - ../app-data/spark:/opt/bitnami/spark/data
      - ../configs/hadoop/hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml
    networks:
      - big-data-network
    healthcheck:
      test: ["CMD-SHELL", "python3 -c 'import urllib.request as urllib; import json; res = urllib.urlopen(\"http://localhost:8083/json/\"); data = json.load(res); exit(0) if \"cores\" in data else exit(1)'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 5s

  spark-worker-2:
    image: bitnami/spark:latest
    container_name: spark-worker-2
    environment:
      - HADOOP_CONF_DIR=/opt/bitnami/hadoop/conf
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_PUBLIC_DNS=localhost
      - SPARK_CONF_spark_ui_reverseProxy=true
      - SPARK_WORKER_WEBUI_PORT=8084
    depends_on:
      - spark-master
    ports:
      - "8084:8084"
    volumes:
      - ../configs/spark:/opt/bitnami/spark/conf
      - ../app-data/spark/jars:/opt/bitnami/spark/custom-jars
      - ../app-data/spark:/opt/bitnami/spark/data
      - ../configs/hadoop/hive-site.xml:/opt/bitnami/spark/conf/hive-site.xml
    networks:
      - big-data-network
    healthcheck:
      test: ["CMD-SHELL", "python3 -c 'import urllib.request as urllib; import json; res = urllib.urlopen(\"http://localhost:8084/json/\"); data = json.load(res); exit(0) if \"cores\" in data else exit(1)'"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 5s

networks:
  big-data-network:
    external: true