services:
  hadoop-namenode:
    image: apache/hadoop:3.3.6-arm64
    container_name: hadoop-namenode
    hostname: hadoop-namenode
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:9000
      - HDFS_CONF_dfs_replication=2
      - HDFS_CONF_dfs_namenode_name_dir=file:///hadoop_data/hdfs/namenode
    ports:
      - "9870:9870"  # NameNode Web UI
      - "9000:9000"  # HDFS RPC
    volumes:
      - ./data/hadoop/namenode:/hadoop_data/hdfs/namenode
      - ./configs:/opt/hadoop-3.3.6/etc/hadoop  # Mount configs directory
    command: ["hdfs", "namenode"]
    networks:
      - hadoop

  hadoop-datanode-1:
    image: apache/hadoop:3.3.6-arm64
    container_name: hadoop-datanode-1
    hostname: hadoop-datanode-1
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:9000
      - HDFS_CONF_dfs_datanode_data_dir=file:///hadoop_data/hdfs/datanode
    volumes:
      - ./data/hadoop/datanode-1:/hadoop_data/hdfs/datanode
      - ./configs:/opt/hadoop-3.3.6/etc/hadoop  # Mount configs directory
    depends_on:
      - hadoop-namenode
    command: ["/bin/bash", "-c", "sleep 10 && hdfs datanode"]
    networks:
      - hadoop

  hadoop-datanode-2:
    image: apache/hadoop:3.3.6-arm64
    container_name: hadoop-datanode-2
    hostname: hadoop-datanode-2
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:9000
      - HDFS_CONF_dfs_datanode_data_dir=file:///hadoop_data/hdfs/datanode
    volumes:
      - ./data/hadoop/datanode-2:/hadoop_data/hdfs/datanode
      - ./configs:/opt/hadoop-3.3.6/etc/hadoop  # Mount configs directory
    depends_on:
      - hadoop-namenode
    command: ["/bin/bash", "-c", "sleep 10 && hdfs datanode"]
    networks:
      - hadoop

  yarn-resourcemanager:
    image: apache/hadoop:3.3.6-arm64
    container_name: yarn-resourcemanager
    hostname: yarn-resourcemanager
    environment:
      - YARN_CONF_yarn_resourcemanager_hostname=yarn-resourcemanager
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:9000
      - YARN_CONF_yarn_log_aggregation_enable=true
      - YARN_CONF_yarn_resourcemanager_address=yarn-resourcemanager:8032
      - YARN_CONF_yarn_nodemanager_resource_memory_mb=4096
      - YARN_CONF_yarn_scheduler_maximum_allocation_mb=4096
      - YARN_CONF_yarn_scheduler_minimum_allocation_mb=1024
    ports:
      - "8088:8088"  # ResourceManager Web UI
    volumes:
      - ./configs:/opt/hadoop-3.3.6/etc/hadoop  # Mount configs directory
    depends_on:
      - hadoop-namenode
    command: ["yarn", "resourcemanager"]
    networks:
      - hadoop

  yarn-nodemanager-1:
    image: apache/hadoop:3.3.6-arm64
    container_name: yarn-nodemanager-1
    hostname: yarn-nodemanager-1
    environment:
      - YARN_CONF_yarn_resourcemanager_hostname=yarn-resourcemanager
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:9000
      - YARN_CONF_yarn_nodemanager_resource_memory_mb=4096
      - YARN_CONF_yarn_scheduler_maximum_allocation_mb=4096
      - YARN_CONF_yarn_scheduler_minimum_allocation_mb=1024
    volumes:
      - ./configs:/opt/hadoop-3.3.6/etc/hadoop  # Mount configs directory
    depends_on:
      - yarn-resourcemanager
    command: ["/bin/bash", "-c", "sleep 15 && yarn nodemanager"]
    networks:
      - hadoop

  yarn-nodemanager-2:
    image: apache/hadoop:3.3.6-arm64
    container_name: yarn-nodemanager-2
    hostname: yarn-nodemanager-2
    environment:
      - YARN_CONF_yarn_resourcemanager_hostname=yarn-resourcemanager
      - CORE_CONF_fs_defaultFS=hdfs://hadoop-namenode:9000
      - YARN_CONF_yarn_nodemanager_resource_memory_mb=4096
      - YARN_CONF_yarn_scheduler_maximum_allocation_mb=4096
      - YARN_CONF_yarn_scheduler_minimum_allocation_mb=1024
    volumes:
      - ./configs:/opt/hadoop-3.3.6/etc/hadoop  # Mount configs directory
    depends_on:
      - yarn-resourcemanager
    command: ["/bin/bash", "-c", "sleep 15 && yarn nodemanager"]
    networks:
      - hadoop

  # Spark Master
  spark-master:
    image: bitnami/spark:3.3.0
    container_name: spark-master
    environment:
      - HADOOP_CONF_DIR=/opt/hadoop-3.3.6/etc/hadoop
      - YARN_CONF_DIR=/opt/hadoop-3.3.6/etc/hadoop
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_PUBLIC_DNS=localhost
      - SPARK_CONF_spark_ui_reverseProxy=true
      - SPARK_MASTER_WEBUI_PORT=8080
    ports:
      - "7077:7077"  # Spark master port
      - "8080:8080"  # Spark Web UI
    volumes:
      - ./data/spark/jars:/opt/bitnami/spark/custom-jars
      - ./data/spark/data:/opt/bitnami/spark/data
      - ./configs:/opt/hadoop-3.3.6/etc/hadoop  # Mount Hadoop configs
    depends_on:
      - yarn-resourcemanager
    networks:
      - hadoop

  # Spark Worker 1
  spark-worker-1:
    image: bitnami/spark:3.3.0
    container_name: spark-worker-1
    environment:
      - HADOOP_CONF_DIR=/opt/hadoop-3.3.6/etc/hadoop
      - YARN_CONF_DIR=/opt/hadoop-3.3.6/etc/hadoop
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_PUBLIC_DNS=localhost
      - SPARK_CONF_spark_ui_reverseProxy=true
      - SPARK_WORKER_WEBUI_PORT=8083
    depends_on:
      - spark-master
    ports:
        - "8083:8083"
    volumes:
      - ./data/spark/jars:/opt/bitnami/spark/custom-jars
      - ./data/spark/data:/opt/bitnami/spark/data
      - ./configs:/opt/hadoop-3.3.6/etc/hadoop  # Mount Hadoop configs
    networks:
      - hadoop

  # Spark Worker 2
  spark-worker-2:
    image: bitnami/spark:3.3.0
    container_name: spark-worker-2
    environment:
      - HADOOP_CONF_DIR=/opt/hadoop-3.3.6/etc/hadoop
      - YARN_CONF_DIR=/opt/hadoop-3.3.6/etc/hadoop
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_PUBLIC_DNS=localhost
      - SPARK_CONF_spark_ui_reverseProxy=true
      - SPARK_WORKER_WEBUI_PORT=8084
    depends_on:
      - spark-master
    ports:
        - "8084:8084"
    volumes:
      - ./data/spark/jars:/opt/bitnami/spark/custom-jars
      - ./data/spark/data:/opt/bitnami/spark/data
      - ./configs:/opt/hadoop-3.3.6/etc/hadoop  # Mount Hadoop configs
    networks:
      - hadoop

networks:
  hadoop:
    driver: bridge

volumes:
  namenode-data:
  datanode-data-1:
  datanode-data-2:
